# PFE_NLP  

**Projet de Fin d'Ã‰tudes â€“ Traitement Automatique du Langage Naturel (NLP)**

## ğŸ“Œ Description

Ce projet s'inscrit dans le cadre d'un **Projet de Fin d'Ã‰tudes (PFE)** et porte sur l'exploitation de techniques de **Traitement Automatique du Langage Naturel (NLP)** pour la classification de maladies de vignes Ã  partir de descriptions de symptÃ´mes.

L'objectif est d'analyser, traiter et classifier des descriptions textuelles de symptÃ´mes de maladies de vignes (Mildiou, Black Rot, OÃ¯dium, Esca, etc.) Ã  l'aide de diffÃ©rentes approches de machine learning et deep learning.

Le projet propose trois implÃ©mentations distinctes :
- **TextBlob** : Classification basÃ©e sur Naive Bayes
- **spaCy** : Classification avec le composant textcat de spaCy
- **HuggingFace** : Classification fine-tunÃ©e avec des modÃ¨les transformers (CamemBERT)

---

## ğŸ¯ Objectifs

- PrÃ©traiter des donnÃ©es textuelles de descriptions de symptÃ´mes (nettoyage, tokenisation, vectorisation)
- Extraire des caractÃ©ristiques linguistiques pertinentes
- EntraÃ®ner et Ã©valuer des modÃ¨les de classification de maladies
- Comparer diffÃ©rentes approches NLP (TextBlob, spaCy, HuggingFace)
- Fournir des rÃ©sultats exploitables et reproductibles
- GÃ©nÃ©rer des descriptions de symptÃ´mes Ã  partir d'images (module expÃ©rimental)

---

## âš™ï¸ PrÃ©requis

- Python â‰¥ 3.8
- pip
- (Optionnel) CUDA pour l'accÃ©lÃ©ration GPU avec HuggingFace

---

## ğŸ“¦ Installation

### Cloner le dÃ©pÃ´t :

```bash
git clone https://github.com/LouisT1425/PFE_NLP.git
cd PFE_GITHUB
```

### Installer les dÃ©pendances :

```bash
pip install -r requirements.txt
```

### Installer les modÃ¨les spaCy :

```bash
python -m spacy download fr_core_news_sm
```

---

## ğŸš€ Utilisation

### 1. EntraÃ®ner un modÃ¨le

EntraÃ®ner un modÃ¨le avec un des trois classifieurs disponibles :

```bash
# Avec TextBlob
python scripts/train.py --model textblob --input descriptions.csv --output models/textblob.joblib

# Avec spaCy
python scripts/train.py --model spacy --input descriptions.csv --output models/spacy

# Avec HuggingFace (CamemBERT)
python scripts/train.py --model hf --input descriptions.csv --output models/hf
```

**Options disponibles :**
- `--model` : Choix du modÃ¨le (`textblob`, `spacy`, `hf`)
- `--input` : Fichier CSV contenant les colonnes `description` et `disease`
- `--output` : Chemin de sauvegarde du modÃ¨le
- `--test-size` : Proportion des donnÃ©es pour la validation (dÃ©faut: 0.2)

### 2. Faire des prÃ©dictions

Utiliser un modÃ¨le entraÃ®nÃ© pour prÃ©dire les maladies Ã  partir de descriptions :

```bash
# Avec TextBlob
python scripts/predict.py --model textblob --model-path models/textblob.joblib --input test.csv --output predictions.csv

# Avec spaCy
python scripts/predict.py --model spacy --model-path models/spacy --input test.csv --output predictions.csv

# Avec HuggingFace
python scripts/predict.py --model hf --model-path models/hf --input test.csv --output predictions.csv
```

**Options disponibles :**
- `--model` : Type de modÃ¨le utilisÃ©
- `--model-path` : Chemin vers le modÃ¨le sauvegardÃ©
- `--input` : Fichier CSV contenant les descriptions (colonne `description`)
- `--output` : Fichier CSV de sortie avec les prÃ©dictions

### 3. Comparer les modÃ¨les

Comparer les performances des trois modÃ¨les sur un jeu de test :

```bash
python scripts/compare.py --input test.csv --models-dir models --output-dir predictions
```

**Options disponibles :**
- `--input` : Fichier CSV de test avec colonnes `description` et `disease`
- `--models-dir` : Dossier contenant les modÃ¨les entraÃ®nÃ©s
- `--output-dir` : Dossier de sortie pour les rÃ©sultats (dÃ©faut: `prediction`)

Cette commande gÃ©nÃ¨re :
- `comparison_summary.csv` : Tableau rÃ©capitulatif des mÃ©triques (Accuracy, Precision, Recall, F1-score)
- `confusion_matrix_normalized_*.png` : Matrices de confusion normalisÃ©es pour chaque modÃ¨le

### 4. Module expÃ©rimental : GÃ©nÃ©ration de descriptions Ã  partir d'images

GÃ©nÃ©rer automatiquement des descriptions de symptÃ´mes Ã  partir d'images de vignes :

```bash
python experimental/pipeline.py --input images/ --output descriptions_ia.csv --device auto
```

**Options disponibles :**
- `--input` : Dossier contenant les images Ã  analyser
- `--output` : Fichier CSV de sortie (dÃ©faut: `descriptions_ia.csv`)
- `--device` : Device Ã  utiliser (`auto`, `cpu`, `cuda`)

---

## ğŸ“Š DonnÃ©es

### Format des donnÃ©es

Les fichiers CSV doivent contenir au minimum une colonne `description` avec les descriptions textuelles des symptÃ´mes.

Pour l'entraÃ®nement, une colonne `disease` est Ã©galement requise avec les labels de maladies correspondants.

**Exemple de structure :**

```csv
description,disease
"On constate sur les jeunes feuilles...",Mildiou
"Le feuillage dans son ensemble exhibe...",Black Rot
```

### Fichiers de donnÃ©es

- `descriptions.csv` : Jeu de donnÃ©es d'entraÃ®nement avec descriptions et maladies
- `test.csv` : Jeu de donnÃ©es de test pour l'Ã©valuation

Les donnÃ©es sont automatiquement prÃ©traitÃ©es avant l'apprentissage (normalisation, gestion des encodages, nettoyage).

---

## ğŸ“ˆ RÃ©sultats

Les performances des modÃ¨les sont Ã©valuÃ©es Ã  l'aide de mÃ©triques classiques :

- **Accuracy** : Taux de prÃ©dictions correctes
- **Precision** : PrÃ©cision moyenne (macro)
- **Recall** : Rappel moyen (macro)
- **F1-score** : Score F1 moyen (macro)

Les rÃ©sultats sont sauvegardÃ©s dans un fichier CSV et des matrices de confusion sont gÃ©nÃ©rÃ©es pour chaque modÃ¨le afin de visualiser les performances par classe.

---

## ğŸ—ï¸ Structure du projet

```
PFE_GITHUB/
â”œâ”€â”€ classifiers/          # ImplÃ©mentations des classifieurs
â”‚   â”œâ”€â”€ textblob.py      # ModÃ¨le TextBlob (Naive Bayes)
â”‚   â”œâ”€â”€ spacy.py         # ModÃ¨le spaCy (textcat)
â”‚   â””â”€â”€ huggingface.py   # ModÃ¨le HuggingFace (Transformers)
â”œâ”€â”€ scripts/             # Scripts d'exÃ©cution principaux
â”‚   â”œâ”€â”€ train.py         # EntraÃ®nement des modÃ¨les
â”‚   â”œâ”€â”€ predict.py       # PrÃ©dictions avec modÃ¨les entraÃ®nÃ©s
â”‚   â””â”€â”€ compare.py       # Comparaison des modÃ¨les
â”œâ”€â”€ utils/               # Utilitaires
â”‚   â””â”€â”€ data.py          # Chargement et prÃ©traitement des donnÃ©es
â”œâ”€â”€ experimental/        # Modules expÃ©rimentaux
â”‚   â”œâ”€â”€ pipeline.py      # Pipeline de gÃ©nÃ©ration de descriptions
â”‚   â”œâ”€â”€ image_captioning.py
â”‚   â””â”€â”€ symptom_description.py
â”œâ”€â”€ descriptions.csv     # DonnÃ©es d'entraÃ®nement
â”œâ”€â”€ test.csv            # DonnÃ©es de test
â””â”€â”€ requirements.txt    # DÃ©pendances Python
```

---

## ğŸ§  Technologies utilisÃ©es

- **Python** : Langage de programmation principal
- **Scikit-learn** : MÃ©triques et outils de machine learning
- **Pandas** : Manipulation de donnÃ©es
- **NumPy** : Calculs numÃ©riques
- **TextBlob** : Classification Naive Bayes
- **spaCy** : Traitement NLP avec textcat
- **Transformers (HuggingFace)** : ModÃ¨les de deep learning (CamemBERT)
- **PyTorch** : Framework de deep learning
- **Matplotlib** : Visualisation des rÃ©sultats
- **Joblib** : Sauvegarde/chargement de modÃ¨les

---

## ğŸ‘¤ Auteur

**Louis T.**  
Projet rÃ©alisÃ© dans le cadre d'un Projet de Fin d'Ã‰tudes.

---

## ğŸ“„ Licence

Projet Ã  usage acadÃ©mique.
